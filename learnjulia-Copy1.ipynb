{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with Linear Algebra\n",
    "\n",
    "Julia Matrix Operation is fast. To know how fast it is, you need a benchmark package. Type `]` and `add BenchmarkTools` in your REPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  144 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     99.982 ns (0.00% GC)\n",
       "  median time:      110.144 ns (0.00% GC)\n",
       "  mean time:        128.364 ns (9.09% GC)\n",
       "  maximum time:     56.150 μs (99.68% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     911"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "a = randn(ComplexF64, 4, 4)\n",
    "b = randn(ComplexF64, 4)\n",
    "@benchmark $a*$b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cool, can we be faster? Yes if the matrix is small!\n",
    "\n",
    "For static array, we can avoid all allocations.\n",
    "\n",
    "##### Challenge!\n",
    "Read the document of this package\n",
    "https://github.com/JuliaArrays/StaticArrays.jl\n",
    "and show it is really fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     11.442 ns (0.00% GC)\n",
       "  median time:      11.732 ns (0.00% GC)\n",
       "  mean time:        12.272 ns (0.00% GC)\n",
       "  maximum time:     53.112 ns (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ] add StaticArrays\n",
    "using StaticArrays\n",
    "\n",
    "sa = SMatrix{4, 4}(a)\n",
    "sb = SVector{4}(b)\n",
    "@benchmark $sa*$sb\n",
    "\n",
    "@test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If matrix contraction can not satisfy you, tensor contraction will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7×10 Array{Float64,2}:\n",
       "  3.88092      4.22942  -2.20287   …   4.48744   -12.2507   -1.03379 \n",
       "  3.69114     -6.52209  -6.9612        1.74549    -5.75151  -1.31186 \n",
       "  1.98873      3.22936   0.537409     -2.63146    -7.1749    0.463595\n",
       " -2.06479    -11.1186   -2.61311       1.88026    -6.39603   2.12045 \n",
       " -0.0402845   -2.51435  -0.507906     -1.8457     -5.47197   5.49651 \n",
       " -2.76435      4.70284  -1.07937   …   0.342825   -6.35544  -1.00031 \n",
       " -1.1936       6.40223   0.103184     -2.27151     3.78841  -7.63995 "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ] add TensorOperations\n",
    "using TensorOperations\n",
    "\n",
    "ta = randn(6, 10, 5)\n",
    "tb = randn(6, 5, 7)\n",
    "\n",
    "@tensor tc[l,j] := ta[i,j,k] * tb[i,k,l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cool, see what kind of linear algebras we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = randn(100, 100)\n",
    "\n",
    "using LinearAlgebra\n",
    "# svd decomposition\n",
    "svd(a)\n",
    "# eigen solver\n",
    "eigen(a)\n",
    "# qr decomposition\n",
    "qr(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Arpack [7d9fca2a-8960-54d3-9f78-7d1dccf2cb97]\n",
      "└ @ Base loading.jl:1186\n",
      "ERROR: LoadError: No deps.jl file could be found. Please try running Pkg.build(\"Arpack\").\n",
      "Currently, the build command might fail when Julia has been built from source\n",
      "and the recommendation is to use the official binaries from julialang.org.\n",
      "For more info see https://github.com/JuliaLinearAlgebra/Arpack.jl/issues/5.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope at /home/leo/.julia/packages/Arpack/WP3ru/src/Arpack.jl:19\n",
      " [2] include at ./boot.jl:317 [inlined]\n",
      " [3] include_relative(::Module, ::String) at ./loading.jl:1038\n",
      " [4] include(::Module, ::String) at ./sysimg.jl:29\n",
      " [5] top-level scope at none:2\n",
      " [6] eval at ./boot.jl:319 [inlined]\n",
      " [7] eval(::Expr) at ./client.jl:389\n",
      " [8] top-level scope at ./none:3\n",
      "in expression starting at /home/leo/.julia/packages/Arpack/WP3ru/src/Arpack.jl:16\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Failed to precompile Arpack [7d9fca2a-8960-54d3-9f78-7d1dccf2cb97] to /home/leo/.julia/compiled/v1.0/Arpack/X5VZL.ji.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile Arpack [7d9fca2a-8960-54d3-9f78-7d1dccf2cb97] to /home/leo/.julia/compiled/v1.0/Arpack/X5VZL.ji.",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] macro expansion at ./logging.jl:313 [inlined]",
      " [3] compilecache(::Base.PkgId, ::String) at ./loading.jl:1184",
      " [4] macro expansion at ./logging.jl:311 [inlined]",
      " [5] _require(::Base.PkgId) at ./loading.jl:941",
      " [6] require(::Base.PkgId) at ./loading.jl:852",
      " [7] macro expansion at ./logging.jl:311 [inlined]",
      " [8] require(::Module, ::Symbol) at ./loading.jl:834",
      " [9] top-level scope at In[16]:5"
     ]
    }
   ],
   "source": [
    "using SparseArrays\n",
    "sp = sprand(1000, 1000, 0.01)\n",
    "\n",
    "# ] add Arpack\n",
    "using Arpack\n",
    "eigs(sp, which=\"SA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using KrylovKit\n",
    "\n",
    "sp = sp'+sp\n",
    "vals, vecs, info = eigsolve(sp, 1, :SR);\n",
    "\n",
    "using Test\n",
    "@test vals[1] ≈ minimum(eigen(sp |> Matrix).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m \u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m! \u001b[0m\u001b[1mE\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m rayl\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mg\u001b[22mh\u001b[0m\u001b[1me\u001b[22mxte\u001b[0m\u001b[1mn\u001b[22msion rayl\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mg\u001b[22mhquoti\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22mt G\u001b[0m\u001b[1me\u001b[22mneral\u001b[0m\u001b[1mi\u001b[22mzedEi\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "eigen(A; permute::Bool=true, scale::Bool=true) -> Eigen\n",
       "```\n",
       "\n",
       "Computes the eigenvalue decomposition of `A`, returning an `Eigen` factorization object `F` which contains the eigenvalues in `F.values` and the eigenvectors in the columns of the matrix `F.vectors`. (The `k`th eigenvector can be obtained from the slice `F.vectors[:, k]`.)\n",
       "\n",
       "Iterating the decomposition produces the components `F.values` and `F.vectors`.\n",
       "\n",
       "The following functions are available for `Eigen` objects: [`inv`](@ref), [`det`](@ref), and [`isposdef`](@ref).\n",
       "\n",
       "For general nonsymmetric matrices it is possible to specify how the matrix is balanced before the eigenvector calculation. The option `permute=true` permutes the matrix to become closer to upper triangular, and `scale=true` scales the matrix by its diagonal elements to make rows and columns more equal in norm. The default is `true` for both options.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> F = eigen([1.0 0.0 0.0; 0.0 3.0 0.0; 0.0 0.0 18.0])\n",
       "Eigen{Float64,Float64,Array{Float64,2},Array{Float64,1}}\n",
       "eigenvalues:\n",
       "3-element Array{Float64,1}:\n",
       "  1.0\n",
       "  3.0\n",
       " 18.0\n",
       "eigenvectors:\n",
       "3×3 Array{Float64,2}:\n",
       " 1.0  0.0  0.0\n",
       " 0.0  1.0  0.0\n",
       " 0.0  0.0  1.0\n",
       "\n",
       "julia> F.values\n",
       "3-element Array{Float64,1}:\n",
       "  1.0\n",
       "  3.0\n",
       " 18.0\n",
       "\n",
       "julia> F.vectors\n",
       "3×3 Array{Float64,2}:\n",
       " 1.0  0.0  0.0\n",
       " 0.0  1.0  0.0\n",
       " 0.0  0.0  1.0\n",
       "\n",
       "julia> vals, vecs = F; # destructuring via iteration\n",
       "\n",
       "julia> vals == F.values && vecs == F.vectors\n",
       "true\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "eigen(A, B) -> GeneralizedEigen\n",
       "```\n",
       "\n",
       "Computes the generalized eigenvalue decomposition of `A` and `B`, returning a `GeneralizedEigen` factorization object `F` which contains the generalized eigenvalues in `F.values` and the generalized eigenvectors in the columns of the matrix `F.vectors`. (The `k`th generalized eigenvector can be obtained from the slice `F.vectors[:, k]`.)\n",
       "\n",
       "Iterating the decomposition produces the components `F.values` and `F.vectors`.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> A = [1 0; 0 -1]\n",
       "2×2 Array{Int64,2}:\n",
       " 1   0\n",
       " 0  -1\n",
       "\n",
       "julia> B = [0 1; 1 0]\n",
       "2×2 Array{Int64,2}:\n",
       " 0  1\n",
       " 1  0\n",
       "\n",
       "julia> F = eigen(A, B);\n",
       "\n",
       "julia> F.values\n",
       "2-element Array{Complex{Float64},1}:\n",
       " 0.0 + 1.0im\n",
       " 0.0 - 1.0im\n",
       "\n",
       "julia> F.vectors\n",
       "2×2 Array{Complex{Float64},2}:\n",
       "  0.0-1.0im   0.0+1.0im\n",
       " -1.0-0.0im  -1.0+0.0im\n",
       "\n",
       "julia> vals, vecs = F; # destructuring via iteration\n",
       "\n",
       "julia> vals == F.values && vecs == F.vectors\n",
       "true\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "eigen(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -> Eigen\n",
       "```\n",
       "\n",
       "Computes the eigenvalue decomposition of `A`, returning an `Eigen` factorization object `F` which contains the eigenvalues in `F.values` and the eigenvectors in the columns of the matrix `F.vectors`. (The `k`th eigenvector can be obtained from the slice `F.vectors[:, k]`.)\n",
       "\n",
       "Iterating the decomposition produces the components `F.values` and `F.vectors`.\n",
       "\n",
       "The following functions are available for `Eigen` objects: [`inv`](@ref), [`det`](@ref), and [`isposdef`](@ref).\n",
       "\n",
       "The `UnitRange` `irange` specifies indices of the sorted eigenvalues to search for.\n",
       "\n",
       "!!! note\n",
       "    If `irange` is not `1:n`, where `n` is the dimension of `A`, then the returned factorization will be a *truncated* factorization.\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "eigen(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -> Eigen\n",
       "```\n",
       "\n",
       "Computes the eigenvalue decomposition of `A`, returning an `Eigen` factorization object `F` which contains the eigenvalues in `F.values` and the eigenvectors in the columns of the matrix `F.vectors`. (The `k`th eigenvector can be obtained from the slice `F.vectors[:, k]`.)\n",
       "\n",
       "Iterating the decomposition produces the components `F.values` and `F.vectors`.\n",
       "\n",
       "The following functions are available for `Eigen` objects: [`inv`](@ref), [`det`](@ref), and [`isposdef`](@ref).\n",
       "\n",
       "`vl` is the lower bound of the window of eigenvalues to search for, and `vu` is the upper bound.\n",
       "\n",
       "!!! note\n",
       "    If [`vl`, `vu`] does not contain all eigenvalues of `A`, then the returned factorization will be a *truncated* factorization.\n",
       "\n"
      ],
      "text/plain": [
       "\u001b[36m  eigen(A; permute::Bool=true, scale::Bool=true) -> Eigen\u001b[39m\n",
       "\n",
       "  Computes the eigenvalue decomposition of \u001b[36mA\u001b[39m, returning an \u001b[36mEigen\u001b[39m factorization\n",
       "  object \u001b[36mF\u001b[39m which contains the eigenvalues in \u001b[36mF.values\u001b[39m and the eigenvectors in\n",
       "  the columns of the matrix \u001b[36mF.vectors\u001b[39m. (The \u001b[36mk\u001b[39mth eigenvector can be obtained\n",
       "  from the slice \u001b[36mF.vectors[:, k]\u001b[39m.)\n",
       "\n",
       "  Iterating the decomposition produces the components \u001b[36mF.values\u001b[39m and \u001b[36mF.vectors\u001b[39m.\n",
       "\n",
       "  The following functions are available for \u001b[36mEigen\u001b[39m objects: \u001b[36minv\u001b[39m, \u001b[36mdet\u001b[39m, and\n",
       "  \u001b[36misposdef\u001b[39m.\n",
       "\n",
       "  For general nonsymmetric matrices it is possible to specify how the matrix\n",
       "  is balanced before the eigenvector calculation. The option \u001b[36mpermute=true\u001b[39m\n",
       "  permutes the matrix to become closer to upper triangular, and \u001b[36mscale=true\u001b[39m\n",
       "  scales the matrix by its diagonal elements to make rows and columns more\n",
       "  equal in norm. The default is \u001b[36mtrue\u001b[39m for both options.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> F = eigen([1.0 0.0 0.0; 0.0 3.0 0.0; 0.0 0.0 18.0])\u001b[39m\n",
       "\u001b[36m  Eigen{Float64,Float64,Array{Float64,2},Array{Float64,1}}\u001b[39m\n",
       "\u001b[36m  eigenvalues:\u001b[39m\n",
       "\u001b[36m  3-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m    1.0\u001b[39m\n",
       "\u001b[36m    3.0\u001b[39m\n",
       "\u001b[36m   18.0\u001b[39m\n",
       "\u001b[36m  eigenvectors:\u001b[39m\n",
       "\u001b[36m  3×3 Array{Float64,2}:\u001b[39m\n",
       "\u001b[36m   1.0  0.0  0.0\u001b[39m\n",
       "\u001b[36m   0.0  1.0  0.0\u001b[39m\n",
       "\u001b[36m   0.0  0.0  1.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> F.values\u001b[39m\n",
       "\u001b[36m  3-element Array{Float64,1}:\u001b[39m\n",
       "\u001b[36m    1.0\u001b[39m\n",
       "\u001b[36m    3.0\u001b[39m\n",
       "\u001b[36m   18.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> F.vectors\u001b[39m\n",
       "\u001b[36m  3×3 Array{Float64,2}:\u001b[39m\n",
       "\u001b[36m   1.0  0.0  0.0\u001b[39m\n",
       "\u001b[36m   0.0  1.0  0.0\u001b[39m\n",
       "\u001b[36m   0.0  0.0  1.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> vals, vecs = F; # destructuring via iteration\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> vals == F.values && vecs == F.vectors\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  eigen(A, B) -> GeneralizedEigen\u001b[39m\n",
       "\n",
       "  Computes the generalized eigenvalue decomposition of \u001b[36mA\u001b[39m and \u001b[36mB\u001b[39m, returning a\n",
       "  \u001b[36mGeneralizedEigen\u001b[39m factorization object \u001b[36mF\u001b[39m which contains the generalized\n",
       "  eigenvalues in \u001b[36mF.values\u001b[39m and the generalized eigenvectors in the columns of\n",
       "  the matrix \u001b[36mF.vectors\u001b[39m. (The \u001b[36mk\u001b[39mth generalized eigenvector can be obtained from\n",
       "  the slice \u001b[36mF.vectors[:, k]\u001b[39m.)\n",
       "\n",
       "  Iterating the decomposition produces the components \u001b[36mF.values\u001b[39m and \u001b[36mF.vectors\u001b[39m.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> A = [1 0; 0 -1]\u001b[39m\n",
       "\u001b[36m  2×2 Array{Int64,2}:\u001b[39m\n",
       "\u001b[36m   1   0\u001b[39m\n",
       "\u001b[36m   0  -1\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> B = [0 1; 1 0]\u001b[39m\n",
       "\u001b[36m  2×2 Array{Int64,2}:\u001b[39m\n",
       "\u001b[36m   0  1\u001b[39m\n",
       "\u001b[36m   1  0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> F = eigen(A, B);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> F.values\u001b[39m\n",
       "\u001b[36m  2-element Array{Complex{Float64},1}:\u001b[39m\n",
       "\u001b[36m   0.0 + 1.0im\u001b[39m\n",
       "\u001b[36m   0.0 - 1.0im\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> F.vectors\u001b[39m\n",
       "\u001b[36m  2×2 Array{Complex{Float64},2}:\u001b[39m\n",
       "\u001b[36m    0.0-1.0im   0.0+1.0im\u001b[39m\n",
       "\u001b[36m   -1.0-0.0im  -1.0+0.0im\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> vals, vecs = F; # destructuring via iteration\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> vals == F.values && vecs == F.vectors\u001b[39m\n",
       "\u001b[36m  true\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  eigen(A::Union{SymTridiagonal, Hermitian, Symmetric}, irange::UnitRange) -> Eigen\u001b[39m\n",
       "\n",
       "  Computes the eigenvalue decomposition of \u001b[36mA\u001b[39m, returning an \u001b[36mEigen\u001b[39m factorization\n",
       "  object \u001b[36mF\u001b[39m which contains the eigenvalues in \u001b[36mF.values\u001b[39m and the eigenvectors in\n",
       "  the columns of the matrix \u001b[36mF.vectors\u001b[39m. (The \u001b[36mk\u001b[39mth eigenvector can be obtained\n",
       "  from the slice \u001b[36mF.vectors[:, k]\u001b[39m.)\n",
       "\n",
       "  Iterating the decomposition produces the components \u001b[36mF.values\u001b[39m and \u001b[36mF.vectors\u001b[39m.\n",
       "\n",
       "  The following functions are available for \u001b[36mEigen\u001b[39m objects: \u001b[36minv\u001b[39m, \u001b[36mdet\u001b[39m, and\n",
       "  \u001b[36misposdef\u001b[39m.\n",
       "\n",
       "  The \u001b[36mUnitRange\u001b[39m \u001b[36mirange\u001b[39m specifies indices of the sorted eigenvalues to search\n",
       "  for.\n",
       "\n",
       "\u001b[36m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[36m\u001b[1mNote\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  If \u001b[36mirange\u001b[39m is not \u001b[36m1:n\u001b[39m, where \u001b[36mn\u001b[39m is the dimension of \u001b[36mA\u001b[39m, then the\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  returned factorization will be a \u001b[4mtruncated\u001b[24m factorization.\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  eigen(A::Union{SymTridiagonal, Hermitian, Symmetric}, vl::Real, vu::Real) -> Eigen\u001b[39m\n",
       "\n",
       "  Computes the eigenvalue decomposition of \u001b[36mA\u001b[39m, returning an \u001b[36mEigen\u001b[39m factorization\n",
       "  object \u001b[36mF\u001b[39m which contains the eigenvalues in \u001b[36mF.values\u001b[39m and the eigenvectors in\n",
       "  the columns of the matrix \u001b[36mF.vectors\u001b[39m. (The \u001b[36mk\u001b[39mth eigenvector can be obtained\n",
       "  from the slice \u001b[36mF.vectors[:, k]\u001b[39m.)\n",
       "\n",
       "  Iterating the decomposition produces the components \u001b[36mF.values\u001b[39m and \u001b[36mF.vectors\u001b[39m.\n",
       "\n",
       "  The following functions are available for \u001b[36mEigen\u001b[39m objects: \u001b[36minv\u001b[39m, \u001b[36mdet\u001b[39m, and\n",
       "  \u001b[36misposdef\u001b[39m.\n",
       "\n",
       "  \u001b[36mvl\u001b[39m is the lower bound of the window of eigenvalues to search for, and \u001b[36mvu\u001b[39m is\n",
       "  the upper bound.\n",
       "\n",
       "\u001b[36m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[36m\u001b[1mNote\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  If [\u001b[36mvl\u001b[39m, \u001b[36mvu\u001b[39m] does not contain all eigenvalues of \u001b[36mA\u001b[39m, then the\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  returned factorization will be a \u001b[4mtruncated\u001b[24m factorization."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1me\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "eigsolve(A::AbstractMatrix, [howmany = 1, which = :LM, T = eltype(A)]; kwargs...)\n",
       "eigsolve(f, n::Int, [howmany = 1, which = :LM, T = Float64]; kwargs...)\n",
       "eigsolve(f, x₀, [howmany = 1, which = :LM]; kwargs...)\n",
       "eigsolve(f, x₀, howmany, which, algorithm)\n",
       "```\n",
       "\n",
       "Compute `howmany` eigenvalues from the linear map encoded in the matrix `A` or by the function `f`. Return eigenvalues, eigenvectors and a `ConvergenceInfo` structure.\n",
       "\n",
       "### Arguments:\n",
       "\n",
       "The linear map can be an `AbstractMatrix` (dense or sparse) or a general function or callable object. If an `AbstractMatrix` is used, a starting vector `x₀` does not need to be provided, it is then chosen as `rand(T, size(A,1))`. If the linear map is encoded more generally as a a callable function or method, the best approach is to provide an explicit starting guess `x₀`. Note that `x₀` does not need to be of type `AbstractVector`, any type that behaves as a vector and supports the required methods (see KrylovKit docs) is accepted. If instead of `x₀` an integer `n` is specified, it is assumed that `x₀` is a regular vector and it is initialized to `rand(T,n)`, where the default value of `T` is `Float64`, unless specified differently.\n",
       "\n",
       "The next arguments are optional, but should typically be specified. `howmany` specifies how many eigenvalues should be computed; `which` specifies which eigenvalues should be targetted. Valid specifications of `which` are given by\n",
       "\n",
       "  * `LM`: eigenvalues of largest magnitude\n",
       "  * `LR`: eigenvalues with largest (most positive) real part\n",
       "  * `SR`: eigenvalues with smallest (most negative) real part\n",
       "  * `LI`: eigenvalues with largest (most positive) imaginary part, only if `T <: Complex`\n",
       "  * `SI`: eigenvalues with smallest (most negative) imaginary part, only if `T <: Complex`\n",
       "  * [`ClosestTo(λ)`](@ref): eigenvalues closest to some number `λ`\n",
       "\n",
       "!!! note \"Note about selecting `which` eigenvalues\"\n",
       "    Krylov methods work well for extremal eigenvalues, i.e. eigenvalues on the periphery of the spectrum of the linear map. Even with `ClosestTo`, no shift and invert is performed. This is useful if, e.g., you know the spectrum to be within the unit circle in the complex plane, and want to target the eigenvalues closest to the value `λ = 1`.\n",
       "\n",
       "\n",
       "The argument `T` acts as a hint in which `Number` type the computation should be performed, but is not restrictive. If the linear map automatically produces complex values, complex arithmetic will be used even though `T<:Real` was specified.\n",
       "\n",
       "### Return values:\n",
       "\n",
       "The return value is always of the form `vals, vecs, info = eigsolve(...)` with\n",
       "\n",
       "  * `vals`: a `Vector` containing the eigenvalues, of length at least `howmany`, but could be   longer if more eigenvalues were converged at the same cost. Eigenvalues will be real if   [`Lanczos`](@ref) was used and complex if [`Arnoldi`](@ref) was used (see below).\n",
       "  * `vecs`: a `Vector` of corresponding eigenvectors, of the same length as `vals`. Note that   eigenvectors are not returned as a matrix, as the linear map could act on any custom Julia   type with vector like behavior, i.e. the elements of the list `vecs` are objects that are   typically similar to the starting guess `x₀`, up to a possibly different `eltype`. In particular,   for a general matrix (i.e. with `Arnoldi`) the eigenvectors are generally complex and are   therefore always returned in a complex number format.   When the linear map is a simple `AbstractMatrix`, `vecs` will be `Vector{Vector{<:Number}}`.\n",
       "  * `info`: an object of type [`ConvergenceInfo`], which has the following fields\n",
       "\n",
       "      * `info.converged::Int`: indicates how many eigenvalues and eigenvectors were actually   converged to the specified tolerance `tol` (see below under keyword arguments)\n",
       "      * `info.residual::Vector`: a list of the same length as `vals` containing the residuals   `info.residual[i] = f(vecs[i]) - vals[i] * vecs[i]`\n",
       "      * `info.normres::Vector{<:Real}`: list of the same length as `vals` containing the norm   of the residual `info.normres[i] = norm(info.residual[i])`\n",
       "      * `info.numops::Int`: number of times the linear map was applied, i.e. number of times   `f` was called, or a vector was multiplied with `A`\n",
       "      * `info.numiter::Int`: number of times the Krylov subspace was restarted (see below)\n",
       "\n",
       "!!! warning \"Check for convergence\"\n",
       "    No warning is printed if not all requested eigenvalues were converged, so always check if `info.converged >= howmany`.\n",
       "\n",
       "\n",
       "### Keyword arguments:\n",
       "\n",
       "Keyword arguments and their default values are given by:\n",
       "\n",
       "  * `krylovdim = 30`: the maximum dimension of the Krylov subspace that will be constructed.   Note that the dimension of the vector space is not known or checked, e.g. `x₀` should not   necessarily support the `Base.length` function. If you know the actual problem dimension   is smaller than the default value, it is useful to reduce the value of `krylovdim`, though   in principle this should be detected.\n",
       "  * `tol = 1e-12`: the requested accuracy (corresponding to the 2-norm of the residual for   Schur vectors, not the eigenvectors). If you work in e.g. single precision (`Float32`),   you should definitely change the default value.\n",
       "  * `maxiter = 100`: the number of times the Krylov subspace can be rebuilt; see below for   further details on the algorithms.\n",
       "  * `issymmetric`: if the linear map is symmetric, only meaningful if `T<:Real`\n",
       "  * `ishermitian`: if the linear map is hermitian\n",
       "\n",
       "The default value for the last two depends on the method. If an `AbstractMatrix` is used, `issymmetric` and `ishermitian` are checked for that matrix, ortherwise the default values are `issymmetric = false` and `ishermitian = T <: Real && issymmetric`.\n",
       "\n",
       "### Algorithm\n",
       "\n",
       "The last method, without default values and keyword arguments, is the one that is finally called, and can also be used directly. Here, one specifies the algorithm explicitly as either [`Lanczos`](@ref), for real symmetric or complex hermitian problems, or [`Arnoldi`](@ref), for general problems. Note that these names refer to the process for building the Krylov subspace, but the actual algorithm is an implementation of the Krylov-Schur algorithm, which can dynamically shrink and grow the Krylov subspace, i.e. the restarts are so-called thick restarts where a part of the current Krylov subspace is kept.\n",
       "\n",
       "!!! note \"Note about convergence\"\n",
       "    In case of a general problem, where the `Arnoldi` method is used, convergence of an eigenvalue is not based on the norm of the residual `norm(f(vecs[i]) - vals[i]*vecs[i])` for the eigenvectors but rather on the norm of the residual for the corresponding Schur vectors.\n",
       "\n",
       "    See also [`schursolve`](@ref) if you want to use the partial Schur decomposition directly, or if you are not interested in computing the eigenvectors, and want to work in real arithmetic all the way true (if the linear map and starting guess are real).\n",
       "\n"
      ],
      "text/plain": [
       "\u001b[36m  eigsolve(A::AbstractMatrix, [howmany = 1, which = :LM, T = eltype(A)]; kwargs...)\u001b[39m\n",
       "\u001b[36m  eigsolve(f, n::Int, [howmany = 1, which = :LM, T = Float64]; kwargs...)\u001b[39m\n",
       "\u001b[36m  eigsolve(f, x₀, [howmany = 1, which = :LM]; kwargs...)\u001b[39m\n",
       "\u001b[36m  eigsolve(f, x₀, howmany, which, algorithm)\u001b[39m\n",
       "\n",
       "  Compute \u001b[36mhowmany\u001b[39m eigenvalues from the linear map encoded in the matrix \u001b[36mA\u001b[39m or\n",
       "  by the function \u001b[36mf\u001b[39m. Return eigenvalues, eigenvectors and a \u001b[36mConvergenceInfo\u001b[39m\n",
       "  structure.\n",
       "\n",
       "\u001b[1m  Arguments:\u001b[22m\n",
       "\u001b[1m  ––––––––––––\u001b[22m\n",
       "\n",
       "  The linear map can be an \u001b[36mAbstractMatrix\u001b[39m (dense or sparse) or a general\n",
       "  function or callable object. If an \u001b[36mAbstractMatrix\u001b[39m is used, a starting vector\n",
       "  \u001b[36mx₀\u001b[39m does not need to be provided, it is then chosen as \u001b[36mrand(T, size(A,1))\u001b[39m. If\n",
       "  the linear map is encoded more generally as a a callable function or method,\n",
       "  the best approach is to provide an explicit starting guess \u001b[36mx₀\u001b[39m. Note that \u001b[36mx₀\u001b[39m\n",
       "  does not need to be of type \u001b[36mAbstractVector\u001b[39m, any type that behaves as a\n",
       "  vector and supports the required methods (see KrylovKit docs) is accepted.\n",
       "  If instead of \u001b[36mx₀\u001b[39m an integer \u001b[36mn\u001b[39m is specified, it is assumed that \u001b[36mx₀\u001b[39m is a\n",
       "  regular vector and it is initialized to \u001b[36mrand(T,n)\u001b[39m, where the default value\n",
       "  of \u001b[36mT\u001b[39m is \u001b[36mFloat64\u001b[39m, unless specified differently.\n",
       "\n",
       "  The next arguments are optional, but should typically be specified. \u001b[36mhowmany\u001b[39m\n",
       "  specifies how many eigenvalues should be computed; \u001b[36mwhich\u001b[39m specifies which\n",
       "  eigenvalues should be targetted. Valid specifications of \u001b[36mwhich\u001b[39m are given by\n",
       "\n",
       "    •    \u001b[36mLM\u001b[39m: eigenvalues of largest magnitude\n",
       "\n",
       "    •    \u001b[36mLR\u001b[39m: eigenvalues with largest (most positive) real part\n",
       "\n",
       "    •    \u001b[36mSR\u001b[39m: eigenvalues with smallest (most negative) real part\n",
       "\n",
       "    •    \u001b[36mLI\u001b[39m: eigenvalues with largest (most positive) imaginary part, only\n",
       "        if \u001b[36mT <: Complex\u001b[39m\n",
       "\n",
       "    •    \u001b[36mSI\u001b[39m: eigenvalues with smallest (most negative) imaginary part, only\n",
       "        if \u001b[36mT <: Complex\u001b[39m\n",
       "\n",
       "    •    \u001b[36mClosestTo(λ)\u001b[39m: eigenvalues closest to some number \u001b[36mλ\u001b[39m\n",
       "\n",
       "\u001b[39m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[1mNote about selecting `which` eigenvalues\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  Krylov methods work well for extremal eigenvalues, i.e.\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  eigenvalues on the periphery of the spectrum of the linear map.\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  Even with \u001b[36mClosestTo\u001b[39m, no shift and invert is performed. This is\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  useful if, e.g., you know the spectrum to be within the unit\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  circle in the complex plane, and want to target the eigenvalues\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  closest to the value \u001b[36mλ = 1\u001b[39m.\n",
       "\n",
       "  The argument \u001b[36mT\u001b[39m acts as a hint in which \u001b[36mNumber\u001b[39m type the computation should be\n",
       "  performed, but is not restrictive. If the linear map automatically produces\n",
       "  complex values, complex arithmetic will be used even though \u001b[36mT<:Real\u001b[39m was\n",
       "  specified.\n",
       "\n",
       "\u001b[1m  Return values:\u001b[22m\n",
       "\u001b[1m  ––––––––––––––––\u001b[22m\n",
       "\n",
       "  The return value is always of the form \u001b[36mvals, vecs, info = eigsolve(...)\u001b[39m with\n",
       "\n",
       "    •    \u001b[36mvals\u001b[39m: a \u001b[36mVector\u001b[39m containing the eigenvalues, of length at least\n",
       "        \u001b[36mhowmany\u001b[39m, but could be longer if more eigenvalues were converged at\n",
       "        the same cost. Eigenvalues will be real if \u001b[36mLanczos\u001b[39m was used and\n",
       "        complex if \u001b[36mArnoldi\u001b[39m was used (see below).\n",
       "\n",
       "    •    \u001b[36mvecs\u001b[39m: a \u001b[36mVector\u001b[39m of corresponding eigenvectors, of the same length\n",
       "        as \u001b[36mvals\u001b[39m. Note that eigenvectors are not returned as a matrix, as\n",
       "        the linear map could act on any custom Julia type with vector like\n",
       "        behavior, i.e. the elements of the list \u001b[36mvecs\u001b[39m are objects that are\n",
       "        typically similar to the starting guess \u001b[36mx₀\u001b[39m, up to a possibly\n",
       "        different \u001b[36meltype\u001b[39m. In particular, for a general matrix (i.e. with\n",
       "        \u001b[36mArnoldi\u001b[39m) the eigenvectors are generally complex and are therefore\n",
       "        always returned in a complex number format. When the linear map is\n",
       "        a simple \u001b[36mAbstractMatrix\u001b[39m, \u001b[36mvecs\u001b[39m will be \u001b[36mVector{Vector{<:Number}}\u001b[39m.\n",
       "\n",
       "    •    \u001b[36minfo\u001b[39m: an object of type [\u001b[36mConvergenceInfo\u001b[39m], which has the following\n",
       "        fields\n",
       "      \n",
       "          •    \u001b[36minfo.converged::Int\u001b[39m: indicates how many eigenvalues and\n",
       "              eigenvectors were actually converged to the specified\n",
       "              tolerance \u001b[36mtol\u001b[39m (see below under keyword arguments)\n",
       "      \n",
       "          •    \u001b[36minfo.residual::Vector\u001b[39m: a list of the same length as \u001b[36mvals\u001b[39m\n",
       "              containing the residuals \u001b[36minfo.residual[i] = f(vecs[i]) -\n",
       "              vals[i] * vecs[i]\u001b[39m\n",
       "      \n",
       "          •    \u001b[36minfo.normres::Vector{<:Real}\u001b[39m: list of the same length as\n",
       "              \u001b[36mvals\u001b[39m containing the norm of the residual \u001b[36minfo.normres[i]\n",
       "              = norm(info.residual[i])\u001b[39m\n",
       "      \n",
       "          •    \u001b[36minfo.numops::Int\u001b[39m: number of times the linear map was\n",
       "              applied, i.e. number of times \u001b[36mf\u001b[39m was called, or a vector\n",
       "              was multiplied with \u001b[36mA\u001b[39m\n",
       "      \n",
       "          •    \u001b[36minfo.numiter::Int\u001b[39m: number of times the Krylov subspace\n",
       "              was restarted (see below)\n",
       "\n",
       "\u001b[39m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[1mCheck for convergence\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  No warning is printed if not all requested eigenvalues were\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  converged, so always check if \u001b[36minfo.converged >= howmany\u001b[39m.\n",
       "\n",
       "\u001b[1m  Keyword arguments:\u001b[22m\n",
       "\u001b[1m  ––––––––––––––––––––\u001b[22m\n",
       "\n",
       "  Keyword arguments and their default values are given by:\n",
       "\n",
       "    •    \u001b[36mkrylovdim = 30\u001b[39m: the maximum dimension of the Krylov subspace that\n",
       "        will be constructed. Note that the dimension of the vector space\n",
       "        is not known or checked, e.g. \u001b[36mx₀\u001b[39m should not necessarily support\n",
       "        the \u001b[36mBase.length\u001b[39m function. If you know the actual problem dimension\n",
       "        is smaller than the default value, it is useful to reduce the\n",
       "        value of \u001b[36mkrylovdim\u001b[39m, though in principle this should be detected.\n",
       "\n",
       "    •    \u001b[36mtol = 1e-12\u001b[39m: the requested accuracy (corresponding to the 2-norm\n",
       "        of the residual for Schur vectors, not the eigenvectors). If you\n",
       "        work in e.g. single precision (\u001b[36mFloat32\u001b[39m), you should definitely\n",
       "        change the default value.\n",
       "\n",
       "    •    \u001b[36mmaxiter = 100\u001b[39m: the number of times the Krylov subspace can be\n",
       "        rebuilt; see below for further details on the algorithms.\n",
       "\n",
       "    •    \u001b[36missymmetric\u001b[39m: if the linear map is symmetric, only meaningful if\n",
       "        \u001b[36mT<:Real\u001b[39m\n",
       "\n",
       "    •    \u001b[36mishermitian\u001b[39m: if the linear map is hermitian\n",
       "\n",
       "  The default value for the last two depends on the method. If an\n",
       "  \u001b[36mAbstractMatrix\u001b[39m is used, \u001b[36missymmetric\u001b[39m and \u001b[36mishermitian\u001b[39m are checked for that\n",
       "  matrix, ortherwise the default values are \u001b[36missymmetric = false\u001b[39m and\n",
       "  \u001b[36mishermitian = T <: Real && issymmetric\u001b[39m.\n",
       "\n",
       "\u001b[1m  Algorithm\u001b[22m\n",
       "\u001b[1m  –––––––––––\u001b[22m\n",
       "\n",
       "  The last method, without default values and keyword arguments, is the one\n",
       "  that is finally called, and can also be used directly. Here, one specifies\n",
       "  the algorithm explicitly as either \u001b[36mLanczos\u001b[39m, for real symmetric or complex\n",
       "  hermitian problems, or \u001b[36mArnoldi\u001b[39m, for general problems. Note that these names\n",
       "  refer to the process for building the Krylov subspace, but the actual\n",
       "  algorithm is an implementation of the Krylov-Schur algorithm, which can\n",
       "  dynamically shrink and grow the Krylov subspace, i.e. the restarts are\n",
       "  so-called thick restarts where a part of the current Krylov subspace is\n",
       "  kept.\n",
       "\n",
       "\u001b[39m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[1mNote about convergence\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  In case of a general problem, where the \u001b[36mArnoldi\u001b[39m method is used,\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  convergence of an eigenvalue is not based on the norm of the\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  residual \u001b[36mnorm(f(vecs[i]) - vals[i]*vecs[i])\u001b[39m for the eigenvectors\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  but rather on the norm of the residual for the corresponding Schur\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  vectors.\n",
       "\u001b[39m\u001b[1m  │\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  See also \u001b[36mschursolve\u001b[39m if you want to use the partial Schur\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  decomposition directly, or if you are not interested in computing\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  the eigenvectors, and want to work in real arithmetic all the way\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  true (if the linear map and starting guess are real)."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?eigsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles\n",
    "\n",
    "a = randn(ComplexF64, 3,3)\n",
    "open(\"test.dat\", \"w\") do f\n",
    "    writedlm(f, a)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Complex{Float64},1}:\n",
       "  1.2601337618884032 - 0.02995058821260156im\n",
       " -0.4040283034459509 - 0.24804825719381837im\n",
       " 0.07503132729439094 - 0.0833673573023801im \n",
       " -0.2387132866942657 - 0.46710589398181934im"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"test.dat\", \"r\") do f\n",
    "    b = readdlm(f)\n",
    "end\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, you can embrace the world of Notebooks!\n",
    "# But not programmer's world\n",
    "# This is why we have the next session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       "  1\n",
       "  4\n",
       "  9\n",
       " 16"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = x^2\n",
    "function f(x::Vector{T}) where T\n",
    "    append!(copy(x), x)\n",
    "end\n",
    "@test f(3) == 9\n",
    "\n",
    "x = [1,2,3,4]\n",
    "f.(x)   # now we must add a `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 1, 2, 3, 4]\n",
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "function f(x::Vector{T}) where T\n",
    "    append!(copy(x), x)\n",
    "end\n",
    "\n",
    "x = [1,2,3,4]\n",
    "println(f(x))  # calling the vector version function\n",
    "println(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 1, 2, 3, 4]\n",
      "[1, 2, 3, 4, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# inplace vector version of f\n",
    "function f!(x::Vector{T}) where T\n",
    "    append!(x, x)\n",
    "end\n",
    "\n",
    "x = [1,2,3,4]\n",
    "println(f!(x))\n",
    "x |> println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love China!\n",
      "II lovelove China!China!\n"
     ]
    }
   ],
   "source": [
    "f(x::String, y::String) = x * \" \" * y\n",
    "f(x::String) = x^2\n",
    "\n",
    "x = [\"I\", \"love\", \"China!\"]\n",
    "reduce(f, x) |> println\n",
    "mapreduce(f, f, x) |> println"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap up\n",
    "* multiple dispatch -> function name can be reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But Why do we prefer multiple-dispatch?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
